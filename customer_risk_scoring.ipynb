{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68c7774",
   "metadata": {},
   "source": [
    "### Customer Credit Risk Analysis with ML & Deep Learning\n",
    "Accurate credit risk assessment is very crucial in modern finance. Lenders must evaluate the likelihood that a customer will repay their debt obligations. In this notebook, I will preprocess the data, apply various models, and evaluate their performance with and without SMOTE (Synthetic Minority Over-sampling Technique) to address class imbalance. \n",
    "\n",
    "\n",
    "[**Data Source:** Kaggle - Credit Risk Customers](https://www.kaggle.com/datasets/ppb00x/credit-risk-customers/data)\n",
    "\n",
    "**Dataset Overview:** The dataset contains information on customers, including demographic details, financial status, and credit history. The target variable, `class`, indicates whether a customer is at high risk - bad (1) or low risk - good (0). Class imbalance is evident in the dataset (`class` has more 1s than 0s). To mitigate this, I use SMOTE to oversample the minority class.\n",
    "\n",
    "\n",
    "#### 1. Load Libraries and Data\n",
    "**Steps:**\n",
    "1. Load dependencies and the dataset.\n",
    "2. Visualize the df and check for missing values (none found in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf300a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46465cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df shape is: (1000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>education</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>45.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>new car</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>53.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                  credit_history  \\\n",
       "0              <0       6.0  critical/other existing credit   \n",
       "1        0<=X<200      48.0                   existing paid   \n",
       "2     no checking      12.0  critical/other existing credit   \n",
       "3              <0      42.0                   existing paid   \n",
       "4              <0      24.0              delayed previously   \n",
       "\n",
       "               purpose  credit_amount    savings_status employment  \\\n",
       "0             radio/tv         1169.0  no known savings        >=7   \n",
       "1             radio/tv         5951.0              <100     1<=X<4   \n",
       "2            education         2096.0              <100     4<=X<7   \n",
       "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
       "4              new car         4870.0              <100     1<=X<4   \n",
       "\n",
       "   installment_commitment     personal_status other_parties  ...  \\\n",
       "0                     4.0         male single          none  ...   \n",
       "1                     2.0  female div/dep/mar          none  ...   \n",
       "2                     2.0         male single          none  ...   \n",
       "3                     2.0         male single     guarantor  ...   \n",
       "4                     3.0         male single          none  ...   \n",
       "\n",
       "   property_magnitude   age  other_payment_plans   housing existing_credits  \\\n",
       "0         real estate  67.0                 none       own              2.0   \n",
       "1         real estate  22.0                 none       own              1.0   \n",
       "2         real estate  49.0                 none       own              1.0   \n",
       "3      life insurance  45.0                 none  for free              1.0   \n",
       "4   no known property  53.0                 none  for free              2.0   \n",
       "\n",
       "                  job num_dependents  own_telephone foreign_worker class  \n",
       "0             skilled            1.0            yes            yes  good  \n",
       "1             skilled            1.0           none            yes   bad  \n",
       "2  unskilled resident            2.0           none            yes  good  \n",
       "3             skilled            2.0           none            yes  good  \n",
       "4             skilled            2.0           none            yes   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/credit_customers.csv')\n",
    "print(\"The df shape is:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a2ded28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   checking_status         1000 non-null   object \n",
      " 1   duration                1000 non-null   float64\n",
      " 2   credit_history          1000 non-null   object \n",
      " 3   purpose                 1000 non-null   object \n",
      " 4   credit_amount           1000 non-null   float64\n",
      " 5   savings_status          1000 non-null   object \n",
      " 6   employment              1000 non-null   object \n",
      " 7   installment_commitment  1000 non-null   float64\n",
      " 8   personal_status         1000 non-null   object \n",
      " 9   other_parties           1000 non-null   object \n",
      " 10  residence_since         1000 non-null   float64\n",
      " 11  property_magnitude      1000 non-null   object \n",
      " 12  age                     1000 non-null   float64\n",
      " 13  other_payment_plans     1000 non-null   object \n",
      " 14  housing                 1000 non-null   object \n",
      " 15  existing_credits        1000 non-null   float64\n",
      " 16  job                     1000 non-null   object \n",
      " 17  num_dependents          1000 non-null   float64\n",
      " 18  own_telephone           1000 non-null   object \n",
      " 19  foreign_worker          1000 non-null   object \n",
      " 20  class                   1000 non-null   object \n",
      "dtypes: float64(7), object(14)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# df.describe()  \n",
    "# df.isnull().sum().plot(kind=\"barh\")\n",
    "\n",
    "# No missing found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604e880",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing\n",
    "**Steps:**\n",
    "1. Split the `personal_status` column into `sex` and `marital_status`.\n",
    "2. Apply ordinal encoding to categorical variables.\n",
    "3. Scale numerical features using `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6262dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital_status\n",
      "single         548\n",
      "div/dep/mar    310\n",
      "mar/wid         92\n",
      "div/sep         50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Divide \"personal_status\" column into two different columns\n",
    "df[[\"sex\", \"marital_status\"]]=df.personal_status.str.split(expand=True)\n",
    "df.drop(columns=[\"personal_status\"], inplace=True)\n",
    "print(df.marital_status.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74228f1",
   "metadata": {},
   "source": [
    "**Encode Categorical Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437daa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "cols_to_encode = [\n",
    "    'checking_status', 'credit_history', 'purpose', 'savings_status', 'employment',\n",
    "    'other_parties', 'property_magnitude', 'other_payment_plans',\n",
    "    'housing', 'job', 'own_telephone', 'foreign_worker', 'class',\n",
    "    'sex', 'marital_status'\n",
    "]\n",
    "\n",
    "df[cols_to_encode] = ord_enc.fit_transform(df[cols_to_encode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e790522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1.0    700\n",
      "0.0    300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"class\"].value_counts())\n",
    "# Suggests class imbalance with more 1s than 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d9da3",
   "metadata": {},
   "source": [
    "**Split Data and Scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2644aa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 21)\n",
      "y_train shape: (800,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271a61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d617e8",
   "metadata": {},
   "source": [
    "#### 3. Modeling and Evaluation\n",
    "\n",
    "##### Custom TensorFlow Deep Learning Model\n",
    "I will first emply a customer Tensorflow wrapper to judge performance of tranditional ML models against the modern techniques. \n",
    "**Architecture:**\n",
    "- Input Layer: Dense layer with ReLU activation.\n",
    "- Hidden Layers: Dense layers with Dropout for regularization.\n",
    "- Output Layer: Dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9faf61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Custom TensorFlow Model\n",
    "class TensorFlowClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, optimizer='adam', dropout_rate=0.2, epochs=50, batch_size=32, learning_rate=0.001, random_state=42):\n",
    "        self.optimizer = optimizer\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.model_ = None\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        tf.random.set_seed(self.random_state)  # Set seed for TensorFlow\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        if self.optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        else:\n",
    "            optimizer = RMSprop(learning_rate=self.learning_rate)\n",
    "            \n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        input_dim = X.shape[1]\n",
    "        self.model_ = self._build_model(input_dim)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "        self.model_.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0, \n",
    "                        validation_split=0.2, callbacks=[early_stopping])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model_.predict(X) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8d969",
   "metadata": {},
   "source": [
    "#### 4. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c4e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions and parameter grids\n",
    "models_and_params = {\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [5, 10, None]\n",
    "        }\n",
    "    },\n",
    "    \"Logistic Reg.\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1.0, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        \"model\": MLPClassifier(max_iter=500, random_state=42),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(64, 32), (100,)],\n",
    "            \"alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    },\n",
    "    \"TF Deep Learning\": {\n",
    "        \"model\": TensorFlowClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"optimizer\": ['adam', 'rmsprop'],\n",
    "            \"dropout_rate\": [0.2, 0.3],\n",
    "            \"epochs\": [50, 100],\n",
    "            \"batch_size\": [32, 64],\n",
    "            \"learning_rate\": [0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33abbec",
   "metadata": {},
   "source": [
    "#### 5. Model Evaluation: With and Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a37ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to train and evaluate models\n",
    "def train_evaluate(X_train, y_train, X_test, y_test, model_name, model, params):\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    \n",
    "    pipeline = Pipeline([('classifier', model)])\n",
    "    grid = GridSearchCV(pipeline, params, scoring='f1', cv=5, n_jobs=-1, verbose=0)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"Best Parameters\": grid.best_params_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d9a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest (No SMOTE)...\n",
      "Tuning Logistic Reg. (No SMOTE)...\n",
      "Tuning Neural Network (No SMOTE)...\n",
      "Tuning TF Deep Learning (No SMOTE)...\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate WITHOUT SMOTE\n",
    "results_no_smote = []\n",
    "for name, mp in models_and_params.items():\n",
    "    results_no_smote.append(train_evaluate(X_train, y_train, X_test, y_test, name + \" (No SMOTE)\", mp[\"model\"], {'classifier__' + k: v for k, v in mp[\"params\"].items()}))\n",
    "results_df_no_smote = pd.DataFrame(results_no_smote).sort_values(by=\"F1 Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f91d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest (SMOTE)...\n",
      "Tuning Logistic Reg. (SMOTE)...\n",
      "Tuning Neural Network (SMOTE)...\n",
      "Tuning TF Deep Learning (SMOTE)...\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate WITH SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "results_smote = []\n",
    "for name, mp in models_and_params.items():\n",
    "    results_smote.append(train_evaluate(X_train_smote, y_train_smote, X_test, y_test, name + \" (SMOTE)\", mp[\"model\"], {'classifier__' + k: v for k, v in mp[\"params\"].items()}))\n",
    "results_df_smote = pd.DataFrame(results_smote).sort_values(by=\"F1 Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d944f",
   "metadata": {},
   "source": [
    "#### 6. Combine and Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f02625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "                         Model Accuracy Precision  Recall F1 Score\n",
      "0     Random Forest (No SMOTE)   76.50%    77.33%  94.33%   84.98%\n",
      "3  TF Deep Learning (No SMOTE)   74.00%    74.59%  95.74%   83.85%\n",
      "2    Neural Network (No SMOTE)   74.50%    81.69%  82.27%   81.98%\n",
      "1     Logistic Reg. (No SMOTE)   72.00%    75.45%  89.36%   81.82%\n",
      "0        Random Forest (SMOTE)   76.00%    80.39%  87.23%   83.67%\n",
      "3     TF Deep Learning (SMOTE)   76.00%    82.52%  83.69%   83.10%\n",
      "2       Neural Network (SMOTE)   74.50%    83.58%  79.43%   81.45%\n",
      "1        Logistic Reg. (SMOTE)   67.00%    82.05%  68.09%   74.42%\n",
      "\n",
      "Best models without SMOTE:\n",
      "                       Model Accuracy Precision  Recall F1 Score  \\\n",
      "0  Random Forest (No SMOTE)   76.50%    77.33%  94.33%   84.98%   \n",
      "\n",
      "                                     Best Parameters  \n",
      "0  {'classifier__max_depth': 10, 'classifier__n_e...  \n",
      "\n",
      "Best models with SMOTE:\n",
      "                    Model Accuracy Precision  Recall F1 Score  \\\n",
      "0  Random Forest (SMOTE)   76.00%    80.39%  87.23%   83.67%   \n",
      "\n",
      "                                     Best Parameters  \n",
      "0  {'classifier__max_depth': None, 'classifier__n...  \n"
     ]
    }
   ],
   "source": [
    "# Combine and compare results\n",
    "results_comparison = pd.concat([results_df_no_smote, results_df_smote])\n",
    "\n",
    "# Format relevant columns as percentages\n",
    "percentage_cols = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results_comparison[percentage_cols] = results_comparison[percentage_cols].applymap(lambda x: f\"{x * 100:.2f}%\")\n",
    "results_df_no_smote[percentage_cols] = results_df_no_smote[percentage_cols].applymap(lambda x: f\"{x * 100:.2f}%\")\n",
    "results_df_smote[percentage_cols] = results_df_smote[percentage_cols].applymap(lambda x: f\"{x * 100:.2f}%\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_comparison[['Model'] + percentage_cols])\n",
    "print(\"\\nBest models without SMOTE:\\n\", results_df_no_smote.head(1))\n",
    "print(\"\\nBest models with SMOTE:\\n\", results_df_smote.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4bb560",
   "metadata": {},
   "source": [
    "#### Results and Conclusions\n",
    "##### Observations\n",
    "- **Best Performing Model (No SMOTE):** Random Forest or MLP had strong F1 performance even without balancing.\n",
    "- **Best Performing Model (SMOTE):** Random Forest (SMOTE) gave balanced performance, improving recall with minimal precision loss.\n",
    "- **Logistic Regression** underperformed under class imbalance, but worked better post-SMOTE.\n",
    "- **Deep Learning (TF)** performed solidly across both setups, slightly behind RF in F1.\n",
    "\n",
    "##### My suggestions: In Words\n",
    "- Random Forest is a robust model under both balanced and imbalanced data. \n",
    "- SMOTE helps improve recall (identifying risky customers), which is crucial in AML/fraud detection.\n",
    "- Custom TF deep nets are effective but require tuning and more compute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
